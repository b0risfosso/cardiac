{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5671577e-0be2-454c-8df5-cebd1824a18c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/b/bio/cardiac/model1/new_env/bin/python'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed1b2928-99dd-42d2-a2e5-252e77ea37ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import numpy as np\n",
    "import spacy\n",
    "import datasets\n",
    "#import torchtext\n",
    "import tqdm\n",
    "import evaluate\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import pyabf\n",
    "import ast\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9cd378cd-222e-4d8d-adb7-3cfa459e6a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "df = pd.read_csv('/Users/b/bio/cardiac/model1/phases.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c7eca53-0c04-4a8a-9234-13c6fc1d98bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_phase_data(df, index):\n",
    "    \"\"\"\n",
    "    Converts string representations of x and y values at a given index in the DataFrame\n",
    "    into a list of (x, y) tuples.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The DataFrame containing the data.\n",
    "    index (int): The index of the data to extract.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of (x, y) tuples.\n",
    "    \"\"\"\n",
    "    phase_x = ast.literal_eval(df['X Values'][index])\n",
    "    phase_y = ast.literal_eval(df['Y Values'][index])\n",
    "    phase_data = list(zip(phase_x, phase_y))\n",
    "    return phase_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e3e37be-9713-4f80-9a03-b2ce1f89ab99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_tuple_list(tuple_list):\n",
    "    flat_list = []\n",
    "    for tup in tuple_list:\n",
    "        flat_list.extend(tup)\n",
    "    return flat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15600d81-7668-43ed-9e9d-4b921fd4713f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_list_numbers(numbers_list, decimals=5):\n",
    "    \"\"\"\n",
    "    Round all numbers in a list to the specified number of decimal places.\n",
    "\n",
    "    Args:\n",
    "    numbers_list (list): The list of numbers.\n",
    "    decimals (int): The number of decimal places to round to.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of rounded numbers.\n",
    "    \"\"\"\n",
    "    return [round(num, decimals) for num in numbers_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "193342c6-ad28-4333-8be9-6e517890d068",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = []\n",
    "index = 0\n",
    "i = 0\n",
    "while index < len(df):\n",
    "    file = df['File Path'][index]\n",
    "    sweepNum = df['Sweep Number'][index]\n",
    "    phaseNum = df['Phase'][index]\n",
    "    abf = pyabf.ABF(file)\n",
    "    abf.setSweep(sweepNum)\n",
    "    \n",
    "    # Extract sweepX and sweepY\n",
    "    sweepX = abf.sweepX\n",
    "    sweepY = abf.sweepY\n",
    "    \n",
    "    # Create a list of tuples (x, y)\n",
    "    totalSweep = list(zip(sweepX, sweepY))\n",
    "    \n",
    "    phase0 = get_phase_data(df, index)\n",
    "    phase1 = get_phase_data(df, index + 1)\n",
    "    phase2 = get_phase_data(df, index + 2)\n",
    "    phase3 = get_phase_data(df, index + 3)\n",
    "    phase4 = get_phase_data(df, index + 4)\n",
    "\n",
    "    data_dict.append({})\n",
    "    data_dict[i][\"input\"] = round_list_numbers(flatten_tuple_list(totalSweep))\n",
    "    data_dict[i][\"output\"] = round_list_numbers(flatten_tuple_list([phase0[0], phase1[0], phase2[0], phase3[0], phase4[0], phase4[-1]]))\n",
    "\n",
    "    \n",
    "    index+=5\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb911172-741f-469b-8643-ba4bf729cfed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12]\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "lst = [len(data_dict[x][\"output\"]) for x in range(len(data_dict))]\n",
    "print(lst)\n",
    "print(len(lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7ca6f6e-22e7-480f-9b3d-bfd17693e950",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def split_data_dict(data_dict, train_ratio=0.8, val_ratio=0.1, test_ratio=0.1):\n",
    "    # Ensure the ratios add up to 1\n",
    "    assert train_ratio + val_ratio + test_ratio == 1.0, \"Ratios must sum to 1\"\n",
    "    \n",
    "    total_length = len(data_dict)\n",
    "    train_index = int(total_length * train_ratio)\n",
    "    val_index = train_index + int(total_length * val_ratio)\n",
    "    \n",
    "\n",
    "    train_data = data_dict[:train_index]\n",
    "    val_data = data_dict[train_index:val_index]\n",
    "    test_data = data_dict[val_index:]\n",
    "    \n",
    "    return train_data, val_data, test_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4126ab57-90c2-4625-8dc2-4917e77dc590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "2\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "# split dataset 80/10/10\n",
    "\n",
    "train_data, valid_data, test_data = split_data_dict(data_dict)\n",
    "print(len(train_data))\n",
    "print(len(valid_data))\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dcc6930f-ebf4-4408-9e9f-587c785c70b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.025,\n",
       " -82.1228,\n",
       " 0.035,\n",
       " 54.01611,\n",
       " 0.1,\n",
       " 37.20093,\n",
       " 0.3,\n",
       " 9.61304,\n",
       " 0.45,\n",
       " -79.07104,\n",
       " 1.9999,\n",
       " -82.51953]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0][\"output\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b2613d40-461a-4808-af11-a9bf9d0c3f12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n{0: <unk>,\\n 1: <pad>,\\n 2: <sos>,\\n 3: <eos>,\\n 4: 0.0,\\n 5: -79.58984,\\n 6: 0.00005,\\n 7: -79.55933,\\n ...\\n }\\n '"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vocab...\n",
    "\n",
    "\"\"\"\n",
    "{0: <unk>,\n",
    " 1: <pad>,\n",
    " 2: <sos>,\n",
    " 3: <eos>,\n",
    " 4: 0.0,\n",
    " 5: -79.58984,\n",
    " 6: 0.00005,\n",
    " 7: -79.55933,\n",
    " ...\n",
    " }\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7568f95-62b3-40e7-9d18-021383b80160",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "99a65cb5-e3c2-4e72-94fb-8eb0ceb37306",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_example(example, sos_token, eos_token):\n",
    "    input_tokens = [str(num) for num in example[\"input\"]]\n",
    "    output_tokens = [str(num) for num in example[\"output\"]]\n",
    "    input_tokens = [sos_token] + input_tokens + [eos_token]\n",
    "    output_tokens = [sos_token] + output_tokens + [eos_token]\n",
    "    return {\"input_tokens\": input_tokens, \"output_tokens\": output_tokens}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5480a879-61c2-426e-a78f-0f7501c9d376",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cd9a12-9679-4a58-8491-5c8bce1da9e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6282fcfa-df5a-4998-a769-9d11ef306d46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f89abb-7201-414c-b205-c8eb68554b21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "079b153b-13ff-4d6e-a643-3f7c92c4d79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sos_token = \"<sos>\"\n",
    "eos_token = \"<eos>\"\n",
    "\n",
    "fn_kwargs = {\n",
    "    \"sos_token\": sos_token, \n",
    "    \"eos_token\": eos_token\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1a44ecb9-f560-404a-a29d-77160048e42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = Dataset.from_list(train_data)\n",
    "valid_data = Dataset.from_list(valid_data)\n",
    "test_data = Dataset.from_list(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328ae1a0-0a5f-493b-8f0a-ea5e99b682d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b370be36-43a8-4cf6-99c3-084f88333f38",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def tokenize_example(example, sos_token, eos_token):\n",
    "    input_tokens = [str(num) for num in example[\"input\"]]\n",
    "    output_tokens = [str(num) for num in example[\"output\"]]\n",
    "    input_tokens = [sos_token] + input_tokens + [eos_token]\n",
    "    output_tokens = [sos_token] + output_tokens + [eos_token]\n",
    "    return {\"input_tokens\": input_tokens, \"output_tokens\": output_tokens}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa543c3-e5e6-41c0-b22c-fb5c62c30d0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c9ac2dbd-17d3-4214-8d51-399e003bd882",
   "metadata": {},
   "outputs": [],
   "source": [
    "sos_token = \"<sos>\"\n",
    "eos_token = \"<eos>\"\n",
    "\n",
    "fn_kwargs = {\n",
    "    \"sos_token\": sos_token, \n",
    "    \"eos_token\": eos_token\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2d28e4b9-55f1-4ada-865c-a696550c8d10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "934bd01620a249198e0ff1d315ddf69c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/21 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76ceeb095b0142d7973a4f3ed91adb86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "704fe764cbeb4c08ad874b73c0dd2d8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data = train_data.map(lambda x: tokenize_example(x, **fn_kwargs))\n",
    "valid_data = valid_data.map(lambda x: tokenize_example(x, **fn_kwargs))\n",
    "test_data = test_data.map(lambda x: tokenize_example(x, **fn_kwargs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "40599881-2b76-4900-a89a-7a5b03458ae2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<sos>',\n",
       " '0.025',\n",
       " '-82.1228',\n",
       " '0.035',\n",
       " '54.01611',\n",
       " '0.1',\n",
       " '37.20093',\n",
       " '0.3',\n",
       " '9.61304',\n",
       " '0.45',\n",
       " '-79.07104',\n",
       " '1.9999',\n",
       " '-82.51953',\n",
       " '<eos>']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]['output_tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d3b4f29b-8493-42a0-80eb-f154dd6c4293",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "\n",
    "class Vocab:\n",
    "    def __init__(self, token_to_index, unk_token=\"<unk>\"):\n",
    "        self.token_to_index = token_to_index\n",
    "        self.index_to_token = {idx:token for token,idx in token_to_index.items()}\n",
    "        self.unk_token = unk_token\n",
    "        self.unk_index = token_to_index[unk_token]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.token_to_index)\n",
    "\n",
    "    def __getitem__(self, token):\n",
    "        return self.token_to_index.get(token, self.unk_index)\n",
    "\n",
    "    def token_to_idx(self, token):\n",
    "        return self.__getitem__(token)\n",
    "\n",
    "    def idx_to_token(self, index):\n",
    "        return self.index_to_token.get(index, self.unk_token)\n",
    "\n",
    "    def set_default_token(self, index):\n",
    "        if index == self.unk_index:\n",
    "            return\n",
    "\n",
    "        current_token = self.index_to_token.get(index, None)\n",
    "\n",
    "        if self.unk_token in self.token_to_index and current_token:\n",
    "            self.token_to_index[self.unk_token], self.token_to_index[current_token] = index, self.unk_index\n",
    "\n",
    "        if self.unk_index in self.index_to_token and index in self.index_to_token:\n",
    "            self.index_to_token[self.unk_index], self.index_to_token[index] = self.index_to_token[index], self.index_to_token[self.unk_index]\n",
    "\n",
    "        self.unk_index = index\n",
    "\n",
    "    def get_stoi(self):\n",
    "        return self.token_to_index\n",
    "\n",
    "    def get_itos(self):\n",
    "        return self.index_to_token\n",
    "\n",
    "    def lookup_tokens(self, indices):\n",
    "        if torch.is_tensor(indices):\n",
    "            indices = indices.tolist()\n",
    "\n",
    "        return [self.idx_to_token(index) for index in indices]\n",
    "\n",
    "    def lookup_indices(self, tokens):\n",
    "        return [self.token_to_idx(token) for token in tokens]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "67753b80-b08b-4f7e-a21a-3851301bace7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<unk>': 0, '<pad>': 1, '<sos>': 2, '<eos>': 3, '0.02': 4, '-79.40674': 5, '0.036': 6, '42.51099': 7, '0.08': 8, '22.33887': 9, '0.18': 10, '-1.58691': 11, '0.25': 12, '-77.63672': 13, '1.99995': 14, '-79.49829': 15}\n",
      "0.036\n"
     ]
    }
   ],
   "source": [
    "def build_vocab_from_iterator(iterator, min_freq=1, specials=None):\n",
    "    counter = Counter()\n",
    "    for token in iterator:\n",
    "        counter.update(token)\n",
    "\n",
    "    token_to_index = {}\n",
    "    if specials:\n",
    "        for idx, token in enumerate(specials):\n",
    "            token_to_index[token] = idx\n",
    "\n",
    "    for token, freq in counter.items():\n",
    "        if freq >= min_freq and token not in token_to_index:\n",
    "            token_to_index[token] = len(token_to_index)\n",
    "\n",
    "    unk_token = specials[0] if specials else \"<unk>\"\n",
    "    if unk_token not in token_to_index:\n",
    "        token_to_index[unk_token] = len(token_to_index)\n",
    "\n",
    "    return Vocab(token_to_index, unk_token=unk_token)\n",
    "\n",
    "\n",
    "tokens = [['<sos>',\n",
    "  '0.02',\n",
    "  '-79.40674',\n",
    "  '0.036',\n",
    "  '42.51099',\n",
    "  '0.08',\n",
    "  '22.33887',\n",
    "  '0.18',\n",
    "  '-1.58691',\n",
    "  '0.25',\n",
    "  '-77.63672',\n",
    "  '1.99995',\n",
    "  '-79.49829',\n",
    "  '<eos>']]\n",
    "min_freq = 1\n",
    "specials = [\"<unk>\", \"<pad>\", \"<sos>\", \"<eos>\"]\n",
    "vocab = build_vocab_from_iterator(tokens, min_freq, specials)\n",
    "print(vocab.get_stoi())\n",
    "print(vocab.idx_to_token(6))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7d01dcef-25e8-481b-a063-dab9474edc87",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['<sos>',\n",
       "  '0.025',\n",
       "  '-82.1228',\n",
       "  '0.035',\n",
       "  '54.01611',\n",
       "  '0.1',\n",
       "  '37.20093',\n",
       "  '0.3',\n",
       "  '9.61304',\n",
       "  '0.45',\n",
       "  '-79.07104',\n",
       "  '1.9999',\n",
       "  '-82.51953',\n",
       "  '<eos>'],\n",
       " ['<sos>',\n",
       "  '0.025',\n",
       "  '-82.1228',\n",
       "  '0.035',\n",
       "  '54.01611',\n",
       "  '0.1',\n",
       "  '37.20093',\n",
       "  '0.3',\n",
       "  '9.61304',\n",
       "  '0.45',\n",
       "  '-79.07104',\n",
       "  '1.9999',\n",
       "  '-82.51953',\n",
       "  '<eos>'],\n",
       " ['<sos>',\n",
       "  '0.025',\n",
       "  '-80.10864',\n",
       "  '0.036',\n",
       "  '52.55127',\n",
       "  '0.06',\n",
       "  '38.87939',\n",
       "  '0.23',\n",
       "  '11.38306',\n",
       "  '0.35',\n",
       "  '-78.27759',\n",
       "  '1.9999',\n",
       "  '-80.04761',\n",
       "  '<eos>'],\n",
       " ['<sos>',\n",
       "  '0.025',\n",
       "  '-80.3833',\n",
       "  '0.0345',\n",
       "  '55.29785',\n",
       "  '0.045',\n",
       "  '38.48267',\n",
       "  '0.14',\n",
       "  '12.29858',\n",
       "  '0.23',\n",
       "  '-78.61328',\n",
       "  '1.9999',\n",
       "  '-80.41382',\n",
       "  '<eos>'],\n",
       " ['<sos>',\n",
       "  '0.025',\n",
       "  '-80.01709',\n",
       "  '0.036',\n",
       "  '52.82593',\n",
       "  '0.08',\n",
       "  '37.07886',\n",
       "  '0.27',\n",
       "  '9.3689',\n",
       "  '0.39',\n",
       "  '-78.49121',\n",
       "  '1.9999',\n",
       "  '-80.29175',\n",
       "  '<eos>'],\n",
       " ['<sos>',\n",
       "  '0.025',\n",
       "  '-80.26123',\n",
       "  '0.034',\n",
       "  '56.39648',\n",
       "  '0.08',\n",
       "  '38.05542',\n",
       "  '0.28',\n",
       "  '17.82227',\n",
       "  '0.45',\n",
       "  '-79.31519',\n",
       "  '1.9999',\n",
       "  '-80.10864',\n",
       "  '<eos>'],\n",
       " ['<sos>',\n",
       "  '0.025',\n",
       "  '-79.77295',\n",
       "  '0.035',\n",
       "  '51.54419',\n",
       "  '0.08',\n",
       "  '28.68652',\n",
       "  '0.2',\n",
       "  '5.43213',\n",
       "  '0.28',\n",
       "  '-77.6062',\n",
       "  '1.9999',\n",
       "  '-79.62036',\n",
       "  '<eos>'],\n",
       " ['<sos>',\n",
       "  '0.025',\n",
       "  '-79.8645',\n",
       "  '0.035',\n",
       "  '53.6499',\n",
       "  '0.08',\n",
       "  '29.75464',\n",
       "  '0.2',\n",
       "  '9.552',\n",
       "  '0.3',\n",
       "  '-78.73535',\n",
       "  '1.9999',\n",
       "  '-79.98657',\n",
       "  '<eos>'],\n",
       " ['<sos>',\n",
       "  '0.025',\n",
       "  '-87.86011',\n",
       "  '0.038',\n",
       "  '46.26465',\n",
       "  '0.11',\n",
       "  '32.16553',\n",
       "  '0.35',\n",
       "  '7.41577',\n",
       "  '0.45',\n",
       "  '-85.75439',\n",
       "  '1.99995',\n",
       "  '-87.79907',\n",
       "  '<eos>'],\n",
       " ['<sos>',\n",
       "  '0.01',\n",
       "  '-80.53589',\n",
       "  '0.02',\n",
       "  '48.30933',\n",
       "  '0.041',\n",
       "  '25.08545',\n",
       "  '0.2',\n",
       "  '1.86157',\n",
       "  '0.31',\n",
       "  '-77.54517',\n",
       "  '0.99995',\n",
       "  '-80.26123',\n",
       "  '<eos>'],\n",
       " ['<sos>',\n",
       "  '0.025',\n",
       "  '-71.99097',\n",
       "  '0.034',\n",
       "  '45.1355',\n",
       "  '0.06',\n",
       "  '15.93018',\n",
       "  '0.16',\n",
       "  '-15.68604',\n",
       "  '0.25',\n",
       "  '-70.70923',\n",
       "  '1.9999',\n",
       "  '-73.7915',\n",
       "  '<eos>'],\n",
       " ['<sos>',\n",
       "  '0.025',\n",
       "  '-81.81763',\n",
       "  '0.035',\n",
       "  '47.45483',\n",
       "  '0.08',\n",
       "  '25.81787',\n",
       "  '0.2',\n",
       "  '5.70679',\n",
       "  '0.31',\n",
       "  '-80.81055',\n",
       "  '1.9999',\n",
       "  '-81.54297',\n",
       "  '<eos>'],\n",
       " ['<sos>',\n",
       "  '0.025',\n",
       "  '-84.07593',\n",
       "  '0.034',\n",
       "  '50.59814',\n",
       "  '0.05',\n",
       "  '31.21948',\n",
       "  '0.14',\n",
       "  '-2.0752',\n",
       "  '0.2',\n",
       "  '-82.36694',\n",
       "  '1.99995',\n",
       "  '-84.10645',\n",
       "  '<eos>'],\n",
       " ['<sos>',\n",
       "  '0.025',\n",
       "  '-82.21436',\n",
       "  '0.035',\n",
       "  '41.90063',\n",
       "  '0.04',\n",
       "  '16.6626',\n",
       "  '0.06',\n",
       "  '-52.30713',\n",
       "  '0.1',\n",
       "  '-80.29175',\n",
       "  '1.99995',\n",
       "  '-82.82471',\n",
       "  '<eos>'],\n",
       " ['<sos>',\n",
       "  '0.025',\n",
       "  '-80.62744',\n",
       "  '0.035',\n",
       "  '54.6875',\n",
       "  '0.09',\n",
       "  '34.39331',\n",
       "  '0.32',\n",
       "  '5.58472',\n",
       "  '0.42',\n",
       "  '-77.85034',\n",
       "  '1.99995',\n",
       "  '-80.59692',\n",
       "  '<eos>'],\n",
       " ['<sos>',\n",
       "  '0.025',\n",
       "  '-80.47485',\n",
       "  '0.035',\n",
       "  '51.54419',\n",
       "  '0.07',\n",
       "  '25.63477',\n",
       "  '0.16',\n",
       "  '-1.34277',\n",
       "  '0.23',\n",
       "  '-79.74243',\n",
       "  '1.9999',\n",
       "  '-80.56641',\n",
       "  '<eos>'],\n",
       " ['<sos>',\n",
       "  '0.01',\n",
       "  '-78.00293',\n",
       "  '0.02',\n",
       "  '41.3208',\n",
       "  '0.045',\n",
       "  '13.21411',\n",
       "  '0.11',\n",
       "  '-2.92969',\n",
       "  '0.21',\n",
       "  '-78.09448',\n",
       "  '0.99995',\n",
       "  '-78.09448',\n",
       "  '<eos>'],\n",
       " ['<sos>',\n",
       "  '0.01',\n",
       "  '-78.00293',\n",
       "  '0.02',\n",
       "  '41.3208',\n",
       "  '0.055',\n",
       "  '12.57324',\n",
       "  '0.13',\n",
       "  '-12.87842',\n",
       "  '0.19',\n",
       "  '-77.48413',\n",
       "  '0.99995',\n",
       "  '-78.09448',\n",
       "  '<eos>'],\n",
       " ['<sos>',\n",
       "  '0.01',\n",
       "  '-79.74243',\n",
       "  '0.02',\n",
       "  '50.29297',\n",
       "  '0.09',\n",
       "  '27.31323',\n",
       "  '0.48',\n",
       "  '-18.15796',\n",
       "  '0.53',\n",
       "  '-77.54517',\n",
       "  '0.99995',\n",
       "  '-79.58984',\n",
       "  '<eos>'],\n",
       " ['<sos>',\n",
       "  '0.01',\n",
       "  '-73.15063',\n",
       "  '0.018',\n",
       "  '93.50586',\n",
       "  '0.035',\n",
       "  '33.23364',\n",
       "  '0.2',\n",
       "  '1.64795',\n",
       "  '0.26',\n",
       "  '-71.59424',\n",
       "  '0.99995',\n",
       "  '-73.51685',\n",
       "  '<eos>'],\n",
       " ['<sos>',\n",
       "  '0.01',\n",
       "  '-76.87378',\n",
       "  '0.018',\n",
       "  '77.63672',\n",
       "  '0.06',\n",
       "  '32.01294',\n",
       "  '0.26',\n",
       "  '-0.33569',\n",
       "  '0.31',\n",
       "  '-73.66943',\n",
       "  '0.99995',\n",
       "  '-77.02637',\n",
       "  '<eos>']]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"output_tokens\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b7fb805b-6aa2-4c0f-84eb-3d3e99378152",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_freq = 1\n",
    "unk_token = \"<unk>\"\n",
    "pad_token = \"<pad>\"\n",
    "\n",
    "special_tokens = [\n",
    "    unk_token,\n",
    "    pad_token,\n",
    "    sos_token,\n",
    "    eos_token,\n",
    "]\n",
    "\n",
    "input_vocab = build_vocab_from_iterator(\n",
    "    train_data[\"input_tokens\"],\n",
    "    min_freq=min_freq,\n",
    "    specials=special_tokens,\n",
    ")\n",
    "\n",
    "output_vocab = build_vocab_from_iterator(\n",
    "    train_data[\"output_tokens\"],\n",
    "    min_freq=min_freq,\n",
    "    specials=special_tokens,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "07900f60-bc5a-4f21-b919-46db6ea5f5ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44761\n",
      "157\n"
     ]
    }
   ],
   "source": [
    "print(len(input_vocab))\n",
    "print(len(output_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "80384880-9ca6-4538-8c35-1ead363b4568",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert input_vocab[unk_token] == output_vocab[unk_token]\n",
    "assert output_vocab[pad_token] == input_vocab[pad_token]\n",
    "\n",
    "unk_index = input_vocab[unk_token]\n",
    "pad_index = output_vocab[pad_token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9bd2a959-ed12-45ff-89a3-9b7394ed46cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_vocab.set_default_token(unk_index)\n",
    "output_vocab.set_default_token(unk_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "41aa73fe-8946-4739-a5ea-76968d448d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numericalize_example(example, input_vocab, output_vocab):\n",
    "    input_ids = input_vocab.lookup_indices(example[\"input_tokens\"])\n",
    "    output_ids = output_vocab.lookup_indices(example[\"output_tokens\"])\n",
    "    return {\"input_ids\": input_ids, \"output_ids\": output_ids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a6a2c2a2-3b37-4d7e-a8f5-279c548d4e41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d352be23ea744f29f894ca06e35ad26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/21 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a91d66e593243fab6b87521c42f8c65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fa3847347b340ffb1bce023e1c21fe7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fn_kwargs = {\"input_vocab\": input_vocab, \"output_vocab\": output_vocab}\n",
    "\n",
    "train_data = train_data.map(numericalize_example, fn_kwargs=fn_kwargs)\n",
    "valid_data = valid_data.map(numericalize_example, fn_kwargs=fn_kwargs)\n",
    "test_data = test_data.map(numericalize_example, fn_kwargs=fn_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "945ad20c-4342-4c09-8449-c058383df7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_type = \"torch\"\n",
    "format_columns = [\"input_ids\", \"output_ids\"]\n",
    "\n",
    "train_data = train_data.with_format(\n",
    "    type=data_type, columns=format_columns, output_all_columns=True\n",
    ")\n",
    "\n",
    "valid_data = valid_data.with_format(\n",
    "    type=data_type, columns=format_columns, output_all_columns=True\n",
    ")\n",
    "\n",
    "test_data = test_data.with_format(\n",
    "    type=data_type, columns=format_columns, output_all_columns=True\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7d4ae9a0-3978-446a-8c4b-5b122b8b3b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_collate_fn(pad_index):\n",
    "    def collate_fn(batch):\n",
    "        batch_input_ids = [example[\"input_ids\"] for example in batch]\n",
    "        batch_output_ids = [example[\"output_ids\"] for example in batch]\n",
    "        batch_input_ids = nn.utils.rnn.pad_sequence(batch_input_ids, padding_value=pad_index)\n",
    "        batch_output_ids = nn.utils.rnn.pad_sequence(batch_output_ids, padding_value=pad_index)\n",
    "        batch = {\n",
    "            \"input_ids\": batch_input_ids,\n",
    "            \"output_ids\": batch_output_ids\n",
    "        }\n",
    "        return batch\n",
    "    return collate_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4ba6332f-c0d7-42d2-ad9a-76af7a2da594",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_loader(dataset, batch_size, pad_index, shuffle=False):\n",
    "    collate_fn = get_collate_fn(pad_index)\n",
    "    data_loader = torch.utils.data.DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=batch_size,\n",
    "        collate_fn=collate_fn,\n",
    "        shuffle=shuffle,\n",
    "    )\n",
    "    return data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "23c3dbec-b886-4210-a5e6-6ae0b9c62f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "\n",
    "train_data_loader = get_data_loader(train_data, batch_size, pad_index, shuffle=True)\n",
    "valid_data_loader = get_data_loader(valid_data, batch_size, pad_index)\n",
    "test_data_loader = get_data_loader(test_data, batch_size, pad_index)\n",
    "\n",
    "\n",
    "                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "325a5086-5868-42ed-accd-45ade39ff50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(\n",
    "        self, input_dim, embedding_dim, encoder_hidden_dim, decoder_hidden_dim, dropout\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
    "        self.rnn = nn.GRU(embedding_dim, encoder_hidden_dim, bidirectional=True)\n",
    "        self.fc = nn.Linear(encoder_hidden_dim * 2, decoder_hidden_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src):\n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        outputs, hidden = self.rnn(embedded)\n",
    "        hidden = torch.tanh(\n",
    "            self.fc(torch.cat((hidden[-2, :, :], hidden[-1, :, :]), dim=1))\n",
    "        )\n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0eacd732-458b-4456-9775-94fd5a73dfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, encoder_hidden_dim, decoder_hidden_dim):\n",
    "        super().__init__()\n",
    "        self.attn_fc = nn.Linear((encoder_hidden_dim * 2) + decoder_hidden_dim, decoder_hidden_dim)\n",
    "        self.v_fc = nn.Linear(decoder_hidden_dim, 1, bias=False)\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        src_length = encoder_outputs.shape[0]\n",
    "        hidden = hidden.unsqueeze(1).repeat(1, src_length, 1)\n",
    "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
    "        energy = torch.tanh(self.attn_fc(torch.cat((hidden, encoder_outputs), dim=2)))\n",
    "        attention = self.v_fc(energy).squeeze(2)\n",
    "        return torch.softmax(attention, dim=1)\n",
    "        \n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5f3dd3c2-953e-4036-96f4-a2c22445975e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        output_dim,\n",
    "        embedding_dim,\n",
    "        encoder_hidden_dim,\n",
    "        decoder_hidden_dim,\n",
    "        dropout,\n",
    "        attention,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.output_dim = output_dim\n",
    "        self.attention = attention\n",
    "        self.embedding = nn.Embedding(output_dim, embedding_dim)\n",
    "        self.rnn = nn.GRU(\n",
    "            (encoder_hidden_dim * 2) + embedding_dim, decoder_hidden_dim\n",
    "        )\n",
    "        self.fc_out = nn.Linear(\n",
    "            (encoder_hidden_dim * 2) + decoder_hidden_dim + embedding_dim, output_dim\n",
    "        )\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        input = input.unsqueeze(0)\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        a = self.attention(hidden, encoder_outputs)\n",
    "        a = a.unsqueeze(1)\n",
    "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
    "        weighted = torch.bmm(a, encoder_outputs)\n",
    "        weighted = weighted.permute(1, 0, 2)\n",
    "        output, hidden = self.rnn(torch.cat((embedded, weighted), dim=2), hidden.unsqueeze(0))\n",
    "        output = output.squeeze(0)\n",
    "        weighted = weighted.squeeze(0)\n",
    "        embedded = embedded.squeeze(0)\n",
    "        prediction = self.fc_out(torch.cat((output, weighted, embedded), dim=1))\n",
    "        return prediction, hidden.squeeze(0), a.squeeze(1)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8b05364c-5d84-4d60-ad4d-18e775c92dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, src, trg, teacher_forcing_ratio):\n",
    "        batch_size = src.shape[1]\n",
    "        trg_length = trg.shape[0]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "        outputs = torch.zeros(trg_length, batch_size, trg_vocab_size).to(self.device)\n",
    "        encoder_outputs, hidden = self.encoder(src)\n",
    "        input = trg[0, :]\n",
    "        for t in range(1, trg_length):\n",
    "            output, hidden, _ = self.decoder(input, hidden, encoder_outputs)\n",
    "            outputs[t] = output\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            top1 = output.argmax(1)\n",
    "            input = trg[t] if teacher_force else top1\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7f66b90c-37d0-482c-9f2a-f7aba3e33b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(input_vocab)\n",
    "output_dim = len(output_vocab)\n",
    "encoder_embedding_dim = 256\n",
    "decoder_embedding_dim = 256\n",
    "encoder_hidden_dim = 512\n",
    "decoder_hidden_dim = 512\n",
    "encoder_dropout = 0.5\n",
    "decoder_dropout = 0.5\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "attention = Attention(encoder_hidden_dim, decoder_hidden_dim)\n",
    "\n",
    "encoder = Encoder(\n",
    "    input_dim,\n",
    "    encoder_embedding_dim,\n",
    "    encoder_hidden_dim,\n",
    "    decoder_hidden_dim,\n",
    "    encoder_dropout,\n",
    ")\n",
    "\n",
    "decoder = Decoder(\n",
    "    output_dim,\n",
    "    decoder_embedding_dim,\n",
    "    encoder_hidden_dim,\n",
    "    decoder_hidden_dim,\n",
    "    decoder_dropout,\n",
    "    attention,\n",
    ")\n",
    "\n",
    "model = Seq2Seq(encoder, decoder, device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7ae3dd3b-3f61-442f-8ff5-5d57b4d3c787",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(44761, 256)\n",
       "    (rnn): GRU(256, 512, bidirectional=True)\n",
       "    (fc): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (attention): Attention(\n",
       "      (attn_fc): Linear(in_features=1536, out_features=512, bias=True)\n",
       "      (v_fc): Linear(in_features=512, out_features=1, bias=False)\n",
       "    )\n",
       "    (embedding): Embedding(157, 256)\n",
       "    (rnn): GRU(1280, 512)\n",
       "    (fc_out): Linear(in_features=1792, out_features=157, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        if \"weight\" in name:\n",
    "            nn.init.normal_(param.data, mean=0, std=0.01)\n",
    "        else:\n",
    "            nn.init.constant_(param.data, 0)\n",
    "\n",
    "\n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "28a05a18-77bc-4ab5-aa06-2bf2fa586677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 18,213,789 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "print(f\"The model has {count_parameters(model):,} trainable parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3c7429f4-d323-4319-8b8e-e522f4cc257c",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a55a931f-6b05-440d-99dc-a1edf3ef4d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index=pad_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5275a728-e727-48eb-9985-32e11b8aa2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(\n",
    "    model, data_loader, optimizer, criterion, clip, teacher_forcing_ratio, device\n",
    "):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for i, batch in enumerate(data_loader):\n",
    "        src = batch[\"input_ids\"].to(device)\n",
    "        trg = batch[\"output_ids\"].to(device)\n",
    "        # src = [src length, batch size]\n",
    "        # trg = [trg length, batch size]\n",
    "        optimizer.zero_grad()\n",
    "        output = model(src, trg, teacher_forcing_ratio)\n",
    "        # output = [trg length, batch size, trg vocab size]\n",
    "        output_dim = output.shape[-1]\n",
    "        output = output[1:].view(-1, output_dim)\n",
    "        # output = [(trg length - 1) * batch size, trg vocab size]\n",
    "        trg = trg[1:].view(-1)\n",
    "        # trg = [(trg length - 1) * batch size]\n",
    "        loss = criterion(output, trg)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    return epoch_loss / len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f0bb5c1d-7069-4a93-81ce-663ffa1bb8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_fn(model, data_loader, criterion, device):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(data_loader):\n",
    "            src = batch[\"input_ids\"].to(device)\n",
    "            trg = batch[\"output_ids\"].to(device)\n",
    "            # src = [src length, batch size]\n",
    "            # trg = [trg length, batch size]\n",
    "            output = model(src, trg, 0)  # turn off teacher forcing\n",
    "            # output = [trg length, batch size, trg vocab size]\n",
    "            output_dim = output.shape[-1]\n",
    "            output = output[1:].view(-1, output_dim)\n",
    "            # output = [(trg length - 1) * batch size, trg vocab size]\n",
    "            trg = trg[1:].view(-1)\n",
    "            # trg = [(trg length - 1) * batch size]\n",
    "            loss = criterion(output, trg)\n",
    "            epoch_loss += loss.item()\n",
    "    return epoch_loss / len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764b5230-e2d4-410e-9276-c368423f35b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c29e3b-2c9c-40d6-bff3-f776274057df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                    | 0/10 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "clip = 1.0\n",
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "best_valid_loss = float(\"inf\")\n",
    "\n",
    "for epoch in tqdm.tqdm(range(n_epochs)):\n",
    "    train_loss = train_fn(\n",
    "        model,\n",
    "        train_data_loader,\n",
    "        optimizer,\n",
    "        criterion,\n",
    "        clip,\n",
    "        teacher_forcing_ratio,\n",
    "        device,\n",
    "    )\n",
    "    valid_loss = evaluate_fn(\n",
    "        model,\n",
    "        valid_data_loader,\n",
    "        criterion,\n",
    "        device,\n",
    "    )\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), \"ecg-s2s-model.pt\")\n",
    "    \n",
    "    print(f\"\\tTrain Loss: {train_loss:7.3f} | Train PPL: {np.exp(train_loss):7.3f}\")\n",
    "    print(f\"\\tValid Loss: {valid_loss:7.3f} | Valid PPL: {np.exp(valid_loss):7.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea93f36-f187-438f-852a-1f72d39200be",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"ecg-s2s-model.pt\"))\n",
    "\n",
    "test_loss = evaluate_fn(model, test_data_loader, criterion, device)\n",
    "\n",
    "print(f\"| Test Loss: {test_loss:.3f} | Test PPL: {np.exp(test_loss):7.3f} |\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736aa443-c27b-419f-aa17-a0221fe55718",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_ecg(\n",
    "    data,\n",
    "    model,\n",
    "    output_vocab, \n",
    "    input_vocab,\n",
    "    sos_token,\n",
    "    eos_token,\n",
    "    device,\n",
    "    max_output_length=25,\n",
    "):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # check instance of data\n",
    "        # convert to list of numbers\n",
    "        if isinstance(data[0], str):\n",
    "            input_tokens = [token for token in data]\n",
    "        else:\n",
    "            input_tokens = [str(num) for num in data]\n",
    "        input_tokens = [sos_token] + input_tokens + [eos_token]\n",
    "        ids = input_vocab.lookup_indices(input_tokens)\n",
    "        tensor = torch.LongTensor(ids).unsqueeze(-1).to(device)\n",
    "        encoder_outputs, hidden = model.encoder(tensor)\n",
    "        inputs = output_vocab.lookup_indices([sos_token])\n",
    "        attentions = torch.zeros(max_output_length, 1, len(ids))\n",
    "        for i in range(max_output_length):\n",
    "            input_tensor = torch.LongTensor([inputs[-1]]).to(device)\n",
    "            output, hidden, attention = model.decoder(\n",
    "                input_tensor, hidden, encoder_outputs\n",
    "            )\n",
    "            attentions[i] = attention\n",
    "            predicted_token = output.argmax(-1).item()\n",
    "            inputs.append(predicted_token)\n",
    "            if predicted_token == output_vocab[eos_token]:\n",
    "                break\n",
    "        output_tokens = output_vocab.lookup_tokens(inputs)\n",
    "    return output_tokens, input_tokens, attentions[: len(output_tokens) - 1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdc2503-3453-4982-9509-6e58069f867a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = dataset[0][\"input\"]\n",
    "expected = dataset[0][\"output\"]\n",
    "\n",
    "expected\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453b2706-33c0-441e-a2c3-94c13de3407b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output, data_tokens, attention = classify_ecg(\n",
    "    data,\n",
    "    model, \n",
    "    output_vocab,\n",
    "    input_vocab,\n",
    "    sos_token,\n",
    "    eos_token,\n",
    "    device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b478ce-b113-4e6b-837f-c7661b0bc8dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output, expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885b42f5-227f-4abd-9533-d12231489761",
   "metadata": {},
   "outputs": [],
   "source": [
    "translations = [\n",
    "    classify_ecg(\n",
    "        example[\"input\"],\n",
    "        model,\n",
    "        output_vocab,\n",
    "        input_vocab,\n",
    "        sos_token,\n",
    "        eos_token,\n",
    "        device,\n",
    "    )[0]\n",
    "    for example in tqdm.tqdm(test_data)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82778f07-e7a9-4a54-be8d-55c940182727",
   "metadata": {},
   "outputs": [],
   "source": [
    "bleu = evaluate.load(\"bleu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d13fef-0eb9-4df0-ba5b-e23ab361a4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "translations = [output]\n",
    "predictions = [\" \".join(translation[1:-1]) for translation in translations]\n",
    "\n",
    "references = [[example[\"input\"]] for example in test_data]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f94e5af-b44d-42e1-bf0d-b281d759feea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokenizer_fn():\n",
    "    def tokenizer_fn(s):\n",
    "        if isinstance(s[0], str):\n",
    "            tokens = [token for token in s]\n",
    "        else:\n",
    "            tokens = [str(num) for num in s]\n",
    "        return tokens\n",
    "\n",
    "    return tokenizer_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82de7d5-14eb-4b5d-bfbb-cefc41a1fab1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d7c8fa-a446-4f78-b3bc-ccfbe5dad38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_fn = get_tokenizer_fn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e6686b-c1ba-47a4-8ae1-2d0f02f2174f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5359ea-304d-4e3a-93d0-b6570cf2333c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe995469-43fe-4236-8660-1bf3d5eb5155",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = bleu.compute(\n",
    "    predictions=predictions, references=references, tokenizer=tokenizer_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409b25ef-a028-47d8-8d36-47b362f70aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd505e0c-b580-492f-994d-8d95bb554add",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
